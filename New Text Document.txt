from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout, BatchNormalization,MaxPooling2D, Activation
import tensorflow as tf
from tensorflow import keras
from keras.layers import  GlobalAveragePooling2D
from keras.layers import  ZeroPadding2D
from keras.models import Model
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint


import os
import shutil

# Define the path to the working directory
working_directory_path = '/kaggle/working'

# List all files and directories in the working directory
files_and_dirs = os.listdir(working_directory_path)

# Delete all files and directories in the working directory
for item in files_and_dirs:
    item_path = os.path.join(working_directory_path, item)
    if os.path.isfile(item_path):
        os.remove(item_path)
    elif os.path.isdir(item_path):
        shutil.rmtree(item_path)

# Verify that the working directory is empty
if not os.listdir(working_directory_path):
    print("Working directory is now empty.")
else:
    print("Failed to clear the working directory.")



import cv2
import os

# Define the source directory, working directory, and output directory
source_dir = "/kaggle/input/plant-village-dataset-sajib/plantvillage dataset"
working_dir = "/kaggle/working/dataset_enhanced"

# Function to apply CLAHE to an image
def apply_clahe(image):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)
    return enhanced_img

# Create the working directory if it doesn't exist
os.makedirs(working_dir, exist_ok=True)

# Loop through the source directory and enhance images
for class_name in os.listdir(source_dir):
    class_dir = os.path.join(source_dir, class_name)
    working_class_dir = os.path.join(working_dir, class_name)
    os.makedirs(working_class_dir, exist_ok=True)
    
    for image_name in os.listdir(class_dir):
        image_path = os.path.join(class_dir, image_name)
        img = cv2.imread(image_path)
        enhanced_img = apply_clahe(img)
        
        working_image_path = os.path.join(working_class_dir, image_name)
        cv2.imwrite(working_image_path, enhanced_img)


import cv2
import matplotlib.pyplot as plt
import numpy as np
import os

# Define a function to display images
def display_images(original, preprocessed, title1, title2):
    plt.figure(figsize=(12, 6))
    
    # Display the original image
    plt.subplot(1, 2, 1)
    plt.imshow(original, cmap='gray')
    plt.title(title1)
    
    # Display the preprocessed image
    plt.subplot(1, 2, 2)
    plt.imshow(preprocessed, cmap='gray')
    plt.title(title2)
    
    plt.tight_layout()
    plt.show()

# Example: Load and display the same image in its original and preprocessed forms
image_name = '00075aa8-d81a-4184-8541-b692b78d398a___FREC_Scab 3335.JPG'  # Replace with the actual image name
original_dir = '/kaggle/input/plant-village-dataset-sajib/plantvillage dataset/Apple___Apple_scab/'
preprocessed_dir = '/kaggle/working/dataset_enhanced/Apple___Apple_scab/'  # Path to preprocessed images

original_image_path = os.path.join(original_dir, image_name)
preprocessed_image_path = os.path.join(preprocessed_dir, image_name)

# Check if the image files exist
if not os.path.isfile(original_image_path):
    print(f"Original image file '{image_name}' not found.")
elif not os.path.isfile(preprocessed_image_path):
    print(f"Preprocessed image file '{image_name}' not found.")
else:
    # Load the images
    original_image = cv2.imread(original_image_path)  # Load as grayscale
    preprocessed_image = cv2.imread(preprocessed_image_path)

    # Check if the images were loaded successfully
    if original_image is None:
        print(f"Failed to load the original image: '{image_name}'")
    elif preprocessed_image is None:
        print(f"Failed to load the preprocessed image: '{image_name}'")
    else:
        # Ensure the correct data type (np.uint8)
        original_image = np.array(original_image, dtype=np.uint8)
        preprocessed_image = np.array(preprocessed_image, dtype=np.uint8)

        # Display the images
        display_images(original_image, preprocessed_image, "Original Image", "Preprocessed Image")


import cv2
import os
import random
import matplotlib.pyplot as plt

# Define a function to display images
def display_images(original, preprocessed, title1, title2):
    plt.figure(figsize=(12, 6))
    
    # Display original image
    plt.subplot(1, 2, 1)
    plt.imshow(original, cmap='gray')
    plt.title(title1)
    
    # Display preprocessed image
    plt.subplot(1, 2, 2)
    plt.imshow(preprocessed, cmap='gray')
    plt.title(title2)
    
    plt.tight_layout()
    plt.show()

# Set the path to the directories containing the original and preprocessed images
original_dir = '/kaggle/input/plant-village-dataset-sajib/plantvillage dataset/Apple___Apple_scab'
preprocessed_dir = '/kaggle/working/dataset_enhanced/Apple___Apple_scab/'  # Path to preprocessed images
# Choose 5 random image filenames from the original and preprocessed directories
random_original_images = random.sample(os.listdir(original_dir), 5)
random_preprocessed_images = random.sample(os.listdir(preprocessed_dir), 5)

# Display the randomly selected images
for i in range(5):
    original_image_path = os.path.join(original_dir, random_original_images[i])
    preprocessed_image_path = os.path.join(preprocessed_dir, random_preprocessed_images[i])

    original_image = cv2.imread(original_image_path)
    preprocessed_image = cv2.imread(preprocessed_image_path)

    display_images(original_image, preprocessed_image, "Original Image", "Preprocessed Image")



base_dir_path = '/kaggle/input/plant-village-dataset-sajib/plantvillage dataset'


data_dir_path = '/kaggle/working/dataset_split/'

pip install split-folders

import splitfolders


BATCH_SIZE = 32
IMAGE_SIZE = 256 #make it 256
CHANNEL = 3
EPOCHS = 50 #10
input_shape = (IMAGE_SIZE,IMAGE_SIZE,CHANNEL)
target_size = (IMAGE_SIZE , IMAGE_SIZE)


# Use ImageDataGenerator to rescale the images
train_datagen = ImageDataGenerator( rescale=1./255, horizontal_flip=True)
valid_datagen = ImageDataGenerator( rescale=1./255, horizontal_flip=True)
test_datagen = ImageDataGenerator( rescale=1./255, horizontal_flip=True)


# Load the images
train_generator = train_datagen.flow_from_directory(directory=data_dir_path +'train', 
                                                    target_size=target_size,
                                                   
                                                   
                                                    batch_size=BATCH_SIZE,
                                                    class_mode="categorical",
                                                    shuffle=True,seed=1234)

valid_generator = valid_datagen.flow_from_directory(directory=data_dir_path +'val', 
                                                    target_size=target_size,
                                                   
                                                    batch_size=BATCH_SIZE,
                                                    class_mode="categorical",
                                                    shuffle=True,seed=1234)


test_generator = test_datagen.flow_from_directory(directory=data_dir_path +'test',
                                                  target_size=target_size,
                            
                                                  batch_size=1,
                                                  class_mode=None,
                                                  shuffle=False,
                                                  seed=1234)



len(train_generator)

classes= train_generator.class_indices
class_names = list(classes.keys())
class_names


# Create a new model on top of the ResNet-50 base (you can customize the top layers)
model = Sequential([
    base_model,
    Flatten(),
    Dense(1024, activation='relu'),
    Dense(41, activation='softmax')  # Change num_classes to your desired number
])




# Compile the model
optimizer = Adam(learning_rate=4.0000001899898055e-05, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])



keras.utils.plot_model(model, show_shapes=True)


from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint



# Creating callbacks for the model.
# If the model dosen't continue to improve (loss), the trainning will stop.

# Stop training if loss doesn't keep decreasing.
model_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)
model_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)

# Automatically saves the best weights of the model, based on best val_accuracy
model_mcp = ModelCheckpoint(filepath = "/kaggle/working/model_weights.h5", monitor = 'val_accuracy', 
                      save_best_only = True, verbose = 1)


STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size
STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size
history = model.fit(train_generator,steps_per_epoch=STEP_SIZE_TRAIN,
          validation_data=valid_generator,verbose= 1,
          validation_steps=STEP_SIZE_VALID,epochs=EPOCHS,
                     callbacks=[model_es, model_rlr, model_mcp])



history.history.keys()


acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']



from matplotlib import pyplot as plt
plt.figure(figsize=(6,6))
plt.subplot(1,2,1)
plt.plot(range(EPOCHS),acc , label='Training Accuracy')
plt.plot(range(EPOCHS),val_acc , label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1,2,2)
plt.plot(range(EPOCHS),loss , label='Training Loss')
plt.plot(range(EPOCHS),val_loss , label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()



from matplotlib import pyplot as plt
plt.figure(figsize=(6,6))
plt.subplot(1,2,1)
plt.plot(range(EPOCHS),acc , label='Training Accuracy')
plt.plot(range(EPOCHS),val_acc , label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1,2,2)
plt.plot(range(EPOCHS),loss , label='Training Loss')
plt.plot(range(EPOCHS),val_loss , label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()




model.save("/kaggle/working/model/pbmodel")
model.save("/kaggle/working/model/model.h5")
model.save_weights("/kaggle/working/model/weights.h5")
